#
# Below configurations are to be used with servers/applications built with :
# https://github.com/gjwdyk/NGINX-Notes/tree/main/NMS-Instance-Manager/K8sServer
#

user  nginx;
worker_processes  auto;

#
# Load Module NAP
#
load_module modules/ngx_http_app_protect_module.so;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;



events {
  worker_connections  1024;
}



http {
  include       /etc/nginx/mime.types;
  default_type  application/octet-stream;



  #
  # Following NAP WAF Configurations are Global configurations, applied to ALL "servers"/"locations",
  # and can NOT be moved to lower level, such as "servers"/"locations" level.
  #

  #
  # Horizontal Scaling
  #
  # NGINX App Protect WAF can be deployed in multiple instances that share the traffic to the same applications.
  # In that case all the instances must share the same configuration files as well as the app_protect_cookie_seed directive.
  # As the argument of this directive, put a random alphanumeric string of at least 20 characters length (but not more than 1000 characters).
  #
  # That seed is used by NGINX App Protect WAF to generate the encryption key for the cookies it creates.
  # These cookies are used for various purposes such as validating the integrity of the cookies generated by the application.
  #
  # In the absence of this directive, App Protect generates a random string by itself.
  # In that case, each instance will have a different seed.
  # A cookie created and encrypted on one instance of App Protect will fail to be decrypted when sent by the same client to another App Protect instance having a different encryption key.
  #
  app_protect_cookie_seed app0protect1cookie2seed3app4protect5cookie6seed7app8protect9cookie0seed1app2protect3cookie4seed5app6protect7cookie8seed9;

  #
  # How to handle requests when the App Protect Enforcer cannot process them, either because it is down, disconnected or because of excessive CPU or memory utilization.
  # drop: Drop the request by returning the response “503 Service Unavailable”, a.k.a. “fail-close”.
  # pass: Pass the request without App Protect Enforcer inspection, a.k.a. “fail-open”.
  # Default: pass
  #
  app_protect_failure_mode_action drop;
  # app_protect_failure_mode_action pass;

  #
  # Determines how to handle compressed requests.
  # drop: Drop the request by returning the response “501 Not Implemented”, a.k.a. “fail-close”.
  # pass: Pass the request without App Protect Enforcer inspection, a.k.a. “fail-open”.
  # Default: drop
  #
  app_protect_compressed_requests_action drop;
  # app_protect_compressed_requests_action pass;

  #
  # Determines how to handle requests in case the NGINX request buffer is full and requests cannot be buffered anymore.
  # drop: Drop the request by resetting connection. No response page is returned, a.k.a. “fail-close”.
  # pass: Pass the request without App Protect Enforcer inspection, a.k.a. “fail-open”.
  # Default: pass
  #
  app_protect_request_buffer_overflow_action drop;
  # app_protect_request_buffer_overflow_action pass;



  server_tokens '';         # Remove "NGINX" string from Error Messages, and from HTTP Header "Server".

  log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

  access_log  /var/log/nginx/access.log  main;

  sendfile        on;
  #tcp_nopush     on;

  keepalive_timeout  65;

  #gzip  on;

  include /etc/nginx/conf.d/*.conf;
}



stream {
  upstream server1_tcp_stream {
    zone server1_tcp_stream 32k;
    server $Server1:22;
  }

  server {
    listen 8022;
    status_zone server1_tcp_stream;
    proxy_pass server1_tcp_stream;
    health_check;
    health_check_timeout 9s;
    proxy_timeout 999999999d;         # Time unit reference (https://nginx.org/en/docs/syntax.html)
  }
}
